# 执行计划
- 查看执行过程
````sql
EXPLAIN PLAN  
SELECT *
FROM `hits_100m_obfuscated`

WHERE EventDate = '2013-07-15'

LIMIT 100;
````

- 优化sql语法
```sql

EXPLAIN SYNTAX  
SELECT *
FROM `hits_100m_obfuscated`

WHERE EventDate = '2013-07-15'

LIMIT 100;
```
- 可以看到每个步骤执行线程数
```sql
EXPLAIN PIPELINE  
SELECT *
FROM `hits_100m_obfuscated`

WHERE EventDate = '2013-07-15'

LIMIT 100;

```
# 数据类型
- DateTime clickhouse里面时间类型必须是DateTime类型，避免不必要转换
- 空值Nullable存储 不能用空值存储，会拖累性能，
因为储存Nullable列需要创建一个额外文件来存储NULL的标记，并且Nullable列*无法被索引*
因此除非极端情况，应该*直接使用字段默认值表示空，或者自行指定一个在业务中无意义的值(-1)*

```sql
CREATE TABLE t(x Int8, y Nullable(Int8)) ENGINE TinyLog;
INSERT INTO t VALUES (1, NULL), (2, 3);
SELECT x+y FROM t;
```
在数据目录(data/default/y.null.bin)下面会出现y.null.bin文件，额外存null值，这样不便后续聚合运算

- 分区以及索引
分区粒度根据业务特点决定，一般选择*按天分区*，也可以指定Tuple(),单表一亿条数据为例，分区大小控制在10-30个为最佳
必须指定索引列，clickhouse中*索引列即排序列*，通过*order by*指定，一般在查询条件经常被用来充当筛选条件的属性被纳入
进来；可以是单一纬度，也可以是组合纬度的索引;通常需要满足高级列在前、*查询频率大的在前原则*;还有基数特别大的不适合作为索引列，
不如userid这种，通常*筛选后数据满足在百万以内为最佳*
- 表参数
index_granularity 用来控制索引粒度，默认是8192，不建议调整
- 如果表中不是必须保留全量历史数据，必须ttl，免除手动操作，ttl可以随时通过alter table随时修改
- 写入和删除优化
    - 尽量不要执行单条或者小批量删除和写入操作，这样会产生小分区文件，给后台Merge任务带来巨大压力
    - 不要一次性写入太多分区，或者数据写入太快，数据写入太快会导致Merge速度跟不上而报错，一般建议
    每秒2-3次写入，每次写入2w-5w(官网建议的服务器配置)
    当写入过快时报错处理，采用WAL预写日志，提高写入性能(攒批)，或者降低写入频率

# 常见配置
配置项主要在config.xml(服务端配置)、users.xml(控制使用用户配置，很多配置是按照用户区分)， 
   - cpu资源

     连接ck线程池建议换成连接池，可能会出现关不掉问题

|                   配置                    |                             描述                             |
| :---------------------------------------: | :----------------------------------------------------------: |
|           background_pool_size            | 后台线程池的大小，merge线程就是在线程池中执行，该线程池不仅仅是给merge线程用的，默认16，允许的前提下建议改成**cpu个数2倍** |
|       background_schedule_pool_size       | 执行后台任务的线程数，默认16，建议改成**cpu个数2倍**（线程数） |
| background_distributed_schedule_pool_size | 设置为分布式发送执行后台任务的线程数，默认16，建议改成**cpu个数的2倍（线程数）** |
|          max_concurrent_queries           | 最大并发处理的求请求数（包含select、insert等），默认值100，推荐150（不够再加）-300 |
|                max_threads                |        设置单个查询所能使用的最大cpu个数，默认cpu核数        |



   - 内存资源

|                配置                |                             描述                             |
| :--------------------------------: | :----------------------------------------------------------: |
|          max_memory_usage          | 此参数在users.xml中表示单次query占用内存最大值，该值可以设置的比较大，这样可以提升集群查询的上限。保留一点给os，比如**128G内存的机器，设置为100GB** |
| max_bytes_before_external_group_by | 一般按照max_memory_useage的一半设置内存，当group使用内存超过阈值后会刷新到磁盘进行。因为clickhouse聚合分两个阶段；查询并建立中间数据、合并中间数据，**结合上一项，建议50GB** |
|   max_bytes_before_external_sort   | 当order by已使用max_bytes_before_external_sort内存就进行溢写磁盘(基于磁盘排序)，如果不设置该值，那么当内存不够时直接抛错，设置了该值order by可以正常完成，但是速度相对存内存来说肯定要慢点(实测慢的非常多，无法接受) |
|       max_table_size_to_drop       | 此参数在config.xml中应用于需要删除表或分区的情况，默认是50G，意思是如果删除50GB以上的分区表会失败。建议修改为0，这样不管多大的分区表都可以删除。 |

   
# 存储
clickhouse 不支持设置多数据目录，为了提升数据io性能，可以挂载虚拟卷组绑定多块物理磁盘提升读写性能，多数据查询场景SSD会比普通机械硬盘快2-3倍(运维)
