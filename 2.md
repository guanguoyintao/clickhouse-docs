# 数据类型
1. 建议尽可能使用整形存储，数据失真
2. 布尔型建议使用uint8存储0，1表示
3. decimal，如果有小数统计场景使用该结构，汇率等
4. enum类型，不适用变化比较大的字段，好处是可以对一些状态等做空间优化、数据约束
5. date、datetime、datetime64，时间不建议存字符串可以考虑时间戳，最好存数据类型，方便聚合函数
6. array数组，数组可以使用但是不能嵌套

# 表引擎
1. TinLog本地实验
2. Memory 简单查询快，宕机数据消失，生产环境禁用
3. merge tree
```sql
create table a order mt(
    id Unint32,
    sku String TTL create_time+interval 10 SECOND,// 列级别TTL不能是主键字段，类型必须是日期类型
    amount Decimal(16, 2),
    create_time Datetime,
    INDEX i total_amount TYPE minmax GRANULARITYS 5 //二级索引，在一级索引上再做聚合，GRANULARITYS设定二级索引对一级索引粒度的粒度
) engine = MergeTree
partition by toYYYMMDD(create_time) // 按照时间分区，避免全表扫描的手段
primary key (id) // 1.不唯一 2.一级索引
order by (id, sku),
settings index_granularity = 8192; // 索引粒度，默认会ddl自动创建，当有大量重复值需要修改(调大) 
;

```
面对涉及跨分区的查询统计，clickhouse以分区为单位并行处理。
分区文件格式为日期_最小分区块编号_最大分区块编号_合并等级(被合并次数)，
分区目录下面*.bin、*.mrk3分别为数据文件和标记文件(数据偏移量方便查询)、count.txt存放数据总行数，colums.txt为列信息, *.idx为索引文件(稀疏索引)
数据写入、分区合并：任何一批数据写入都会产生一个临时分区，不会那人已有的分区。写入后某时刻(正常情况下为10-15分钟)，clickhouse会自动触发合并操作(利用optimize语法手动触发也可以)
把临时分区数据合并到已有分区中，并且合并后原始数据还在，只有大合并(10-15分钟)才会清理数据
```sql
optimize table a partition "20201119" final;
```
因为是稀疏索引，根据索引查找类似于二分查找
order by分区内排序，排序是必须的，稀疏索引查找(二分)必须，具体设计根据业务层级纬度，所以主键字段必须是order by前缀，无层级的统计是无意义的。
clickhouse支持二级索引(跳数索引)2020.1(以前是实验功能)以后默认开启，二级索引只有在数据量大，稀疏索引不明显情况下有效果
ttl(time to live) merge tree提供了可以管理数据表或数据列的生命周期的功能(用户画像)，有时需要重启，时间到期会启动一个特殊合并任务，机器资源不够可能会挂掉
列级别会按照列删除，设置默认值，表级别按行做设定动作默认删除(还可以移动)

4. summing merge tree
对于不查询明细，只关心以纬度进行汇总聚合结果场景如果使用普通merge tree，存储空间开销过大、查询时聚合开销过大，
summing merge tree 会做预聚合(定期聚合，分区内聚合，合并时聚合)
```sql
create table b order mt(
    id Unint32,
    sku String,
    amount Decimal(16, 2),
    create_time Datetime,
) engine = SummingMergeTree(create_time) // 参数是想要聚合的列，根据order by做类似group by操作，其他字段取最小一条，如果不填所有非纬度列且数字类型都会聚合
partition by toYYYMMDD(create_time)
primary key (id)
order by (id, sku);
```
单批次会预聚合(同分区)，新版本触发预聚合，聚合以order by作为group by
5. replacing merge tree
定期根据order by去重，去重过程只会在合并过程中出现，并且合并时间是未知的。保证数据最终一致性。去重范围是分区内去重，不能跨分区。适用在后台清除重复数据以节省空间。
```sql
create table b order mt(
    id Unint32,
    sku String,
    amount Decimal(16, 2),
    create_time Datetime,
) engine = ReplacingMergeTree(create_time) // 参数为版本字段，重复数据保留版本最大值，如果没有参数，默认保留插入顺序最后一条
partition by toYYYMMDD(create_time)
primary key (id)
order by (id, sku);
```
单批次会去重(同分区)，新版本触发去重，去重以order by作为唯一键